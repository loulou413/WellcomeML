@article{devlin2019bert,
  title   = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author  = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal = {Proceedings of NAACL-HLT},
  pages   = {4171--4186},
  year    = {2019}
}

@article{vaswani2017attention,
  title   = {Attention is All You Need},
  author  = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, ≈Åukasz and Polosukhin, Illia},
  journal = {Advances in Neural Information Processing Systems},
  volume  = {30},
  year    = {2017}
}

@article{liu2019roberta,
  title   = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  author  = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal = {arXiv preprint arXiv:1907.11692},
  year    = {2019}
}

@misc{wellcome2024,
  title        = {Wellcome Collection},
  author       = {{Wellcome Trust}},
  year         = {2024},
  howpublished = {\url{https://wellcome.org/}},
  note         = {Accessed: 2024}
}

@inproceedings{reimers2019sentence,
  title     = {Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author    = {Reimers, Nils and Gurevych, Iryna},
  booktitle = {Proceedings of EMNLP-IJCNLP},
  pages     = {3982--3992},
  year      = {2019}
}

@misc{missing_values_table,
  title        = {Missing Values Analysis for Wellcome Collection Dataset},
  author       = {Larcher, Louis and Manueguerra, Cassio and Taieb, Arthur},
  year         = {2025},
  howpublished = {\url{Images/NaN_percentage.png}},
  note         = {Statistical analysis of data completeness}
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35f5e0f5",
   "metadata": {},
   "source": [
    "### TF-IDF Baseline: Regression on merged_train. We build a simple baseline using TF-IDF features and Ridge regression to predict `production_date` (year). We'll evaluate on a validation split and then predict missing years to compare later with BERT.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e9ca49",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scripts.helpers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline,BertTokenizer, TrainingArguments, Trainer, BertForSequenceClassification\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mloading\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mformating\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'scripts.helpers'"
     ]
    }
   ],
   "source": [
    "# IMPORT ALL THE NEEDED FILES AND LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import pipeline,BertTokenizer, TrainingArguments, Trainer, BertForSequenceClassification\n",
    "from scripts.helpers import *\n",
    "from scripts.loading import *\n",
    "from scripts.formating import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = load_wellcome_data(n_samples=100000)ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd85fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.80\n",
    "missing_pct = raw_dataset.isnull().sum() / len(raw_dataset)\n",
    "\n",
    "# columns under the threshold\n",
    "cols_to_keep = missing_pct[missing_pct <= threshold].index.tolist()\n",
    "\n",
    "# we get rid of every column with more than treshold% of NaNs except description because of its relevance\n",
    "if \"description\" in raw_dataset.columns and \"description\" not in cols_to_keep:\n",
    "    cols_to_keep.append(\"description\")\n",
    "\n",
    "filtered = raw_dataset[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497f85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = filtered.columns.to_list()\n",
    "print(f'We now have {len(cols)} columns:')\n",
    "print(*cols,sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5737b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of the dataset\n",
    "print(f\"\\nOur filtered dataset has: {filtered.shape[1]} columns and {filtered.shape[0]} rows.\")\n",
    "\n",
    "# how many missing values per column\n",
    "missing_values = filtered.isnull().sum()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Missing Values per Column\")\n",
    "missing_values.plot(kind='bar')\n",
    "plt.ylabel(\"Number of Missing Values\")\n",
    "plt.xlabel(\"Columns\")\n",
    "plt.show();\n",
    "\n",
    "print_one_random_record(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d16cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-predictable columns and with no corelation to the target\n",
    "columns_to_remove = [\n",
    "    # System IDs - just internal database identifiers, not predictable\n",
    "    'id', 'workType_id', 'contributor_ids', 'subject_ids', 'language_ids', \n",
    "    'identifiers', 'sierra_system_number',\n",
    "    \n",
    "    # Counts - database metadata, not intrinsic properties of the work\n",
    "    'items_count', 'parts_count', 'holdings_count', 'images_count',\n",
    "    \n",
    "    # Operational data - library-specific, not about the work itself\n",
    "    'has_digitized_items', 'availability_status',\n",
    "    \n",
    "    # Less useful duplicates - keep the main version, remove auxiliary\n",
    "    'note_types'  # Keep 'notes', remove the types since notes contain more info\n",
    "]\n",
    "necessary_df = filtered.copy().drop(columns=columns_to_remove);\n",
    "\n",
    "# Display percentage of missing values per column with a custom styled table\n",
    "null_pct = necessary_df.isnull().mean().sort_values(ascending=False) * 100\n",
    "train_null = pd.DataFrame({\n",
    "    \"Column\": null_pct.index,\n",
    "    \"% Null\": [f\"{v:.2f}%\" for v in null_pct.values]\n",
    "})\n",
    "\n",
    "css = \"\"\"\n",
    "<style> \n",
    ".table-fixed {border-collapse: collapse; width: 70%; max-width: 900px;} \n",
    ".table-fixed th, \n",
    ".table-fixed td {border: 1px solid #ddd; padding: 6px 10px; text-align: left;} \n",
    ".table-fixed th {background:#808080; font-weight:600;} \n",
    "</style>\n",
    "\"\"\"\n",
    "print('We finally have only those columns left')\n",
    "display(HTML(css + train_null.to_html(index=False, classes=\"table-fixed\", escape=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdefa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_one_random_record(necessary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923282f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_ratio = 0.8\n",
    "train = necessary_df.sample(frac = train_test_ratio, random_state= 42)\n",
    "test = necessary_df.drop(train.index)\n",
    "print(f\"We decide to use {train_test_ratio*100}% of the data for the training.\\n\"\n",
    "      f\"Therefore we have a training sample of size {train.shape} and the test one of size {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c826d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum = train['production_places'].value_counts(normalize=True).cumsum()\n",
    "print(f\"We need the top {(cumsum <= 0.80).sum()} of the values to span 80% of all the production_places inside the dataset\")\n",
    "cumsum = train['languages'].value_counts(normalize=True).cumsum()\n",
    "print(f\"We need the top {(cumsum <= 0.95).sum()} of the values to span 95% of all the languages inside the dataset\")\n",
    "cumsum = train['workType'].value_counts(normalize=True).cumsum()\n",
    "print(f\"We need the top {(cumsum <= 0.95).sum()} of the values to span 95% of all the workType inside the dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in train.columns:\n",
    "    types = train[col].apply(lambda x: type(x).__name__).unique()\n",
    "    print(col, \"->\", types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d620b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afbd0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BIN_SIZE = 30  # Size of year bins (e.g., 30 = bins of 1990-2019, 2020-2049, etc.)\n",
    "MODEL_TYPE = 'logistic'  # Options: 'logistic' or 'random_forest'\n",
    "USE_NUMERICAL_FEATURES = False  # Set to True to add numerical features to TF-\n",
    "\n",
    "MODEL_SAVE_PATH = \"./bin_classification_model.pkl\"\n",
    "VECTORIZER_SAVE_PATH = \"./bin_classification_vectorizer.pkl\"\n",
    "SCALER_SAVE_PATH = \"./bin_classification_scaler.pkl\"\n",
    "\n",
    "print(f\"\\nTraining Data:\")\n",
    "print(f\"  Shape: {merged_train.shape}\")\n",
    "print(f\"  Columns: {list(merged_train.columns)}\")\n",
    "\n",
    "print(f\"\\nTest Data:\")\n",
    "print(f\"  Shape: {test.shape}\")\n",
    "print(f\"  Columns: {list(test.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86d334a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_row(row):\n",
    "    \"\"\"\n",
    "    Format row to match training data format: [COLUMN: {value}]\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for col in row.index:\n",
    "        col_upper = col.upper()\n",
    "        value = row[col]\n",
    "        if pd.isna(value):\n",
    "            value = \"\"\n",
    "        parts.append(f\"[{col_upper}: {{{value}}}]\")\n",
    "    return \" \".join(parts)\n",
    "\n",
    "\n",
    "def create_merged_column_matching_train(df):\n",
    "    \"\"\"\n",
    "    Create MERGED column using the same format as training data\n",
    "    \"\"\"\n",
    "    print(\"\\nCreating MERGED column with format: [COLUMN: {value}]...\")\n",
    "    \n",
    "    # Exclude production_date and thumbnail_url (if exists)\n",
    "    columns_to_merge = [c for c in df.columns \n",
    "                       if c not in [\"production_date\", \"thumbnail_url\", \"year_bin\"]]\n",
    "    \n",
    "    print(f\"  Columns to merge: {columns_to_merge}\")\n",
    "    \n",
    "    # Create a dataframe with only columns to merge\n",
    "    df_for_merge = df[columns_to_merge].copy()\n",
    "    \n",
    "    # Apply formatting\n",
    "    merged_text = df_for_merge.apply(format_row, axis=1)\n",
    "    \n",
    "    # Create result dataframe\n",
    "    result = pd.DataFrame()\n",
    "    result[\"MERGED\"] = merged_text\n",
    "    result[\"production_date\"] = pd.to_numeric(df[\"production_date\"], errors=\"coerce\")\n",
    "    \n",
    "    # Keep year_bin if it exists\n",
    "    if \"year_bin\" in df.columns:\n",
    "        result[\"year_bin\"] = df[\"year_bin\"]\n",
    "    \n",
    "    result = result.reset_index(drop=True)\n",
    "    \n",
    "    print(f\"MERGED column created\")\n",
    "    print(f\" Result shape: {result.shape}\")\n",
    "    \n",
    "    # Show sample\n",
    "    if len(result) > 0:\n",
    "        print(f\"\\n  Sample MERGED text (first 200 chars):\")\n",
    "        print(f\"  {result['MERGED'].iloc[0][:200]}...\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "if 'MERGED' not in test.columns:\n",
    "    print(\"\\nMERGED column not found in test data\")\n",
    "    test_with_merged = create_merged_column_matching_train(test)\n",
    "    \n",
    "    # Replace test with the new version\n",
    "    test = test_with_merged\n",
    "    \n",
    "    print(f\"  Final test shape: {test.shape}\")\n",
    "    print(f\"  Columns: {list(test.columns)}\")\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c044ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_dataset(df, is_train=True):\n",
    "    print(f\"\\nPreprocessing {'training' if is_train else 'test'} data...\")\n",
    "    df = df.copy()\n",
    "    \n",
    "    if 'production_date' in df.columns:\n",
    "        missing_count = df['production_date'].isna().sum()\n",
    "        if missing_count > 0:\n",
    "            median_year = df['production_date'].median()\n",
    "            df['production_date'] = df['production_date'].fillna(median_year)\n",
    "            print(f\"Filled {missing_count} missing dates with median: {median_year}\")\n",
    "    \n",
    "    if 'production_date' in df.columns:\n",
    "        before = len(df)\n",
    "        df = df[(df['production_date'] >= 1465) & (df['production_date'] <= 2025)]\n",
    "        removed = before - len(df)\n",
    "        if removed > 0:\n",
    "            print(f\"Filtered to years 1465-2025: removed {removed} rows ({removed/before*100:.2f}%)\")\n",
    "        print(f\"Year range: {df['production_date'].min():.0f} - {df['production_date'].max():.0f}\")\n",
    "    \n",
    "    if 'MERGED' in df.columns:\n",
    "        df['text_length'] = df['MERGED'].str.len()\n",
    "        df['word_count'] = df['MERGED'].str.split().str.len()\n",
    "        df['avg_word_length'] = df['text_length'] / (df['word_count'] + 1)\n",
    "        print(f\" Created text features\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "train_processed = preprocess_dataset(merged_train, is_train=True)\n",
    "test_processed = preprocess_dataset(test, is_train=False)\n",
    "\n",
    "print(f\"Train shape: {train_processed.shape}\")\n",
    "print(f\"Test shape: {test_processed.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ced3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_bins(df, bin_size):\n",
    "    \"\"\"Create year bins\"\"\"\n",
    "    df = df.copy()\n",
    "    df['year_bin'] = (df['production_date'] // bin_size) * bin_size\n",
    "    df['year_bin_label'] = (df['year_bin'].astype(int).astype(str) + '-' + \n",
    "                           (df['year_bin'] + bin_size - 1).astype(int).astype(str))\n",
    "    return df\n",
    "\n",
    "train_binned = create_bins(train_processed, BIN_SIZE)\n",
    "test_binned = create_bins(test_processed, BIN_SIZE)\n",
    "\n",
    "print(f\"\\nBin size: {BIN_SIZE} years\")\n",
    "print(f\"\\nTraining data:\")\n",
    "print(f\"Samples: {len(train_binned)}\")\n",
    "print(f\"Unique bins: {train_binned['year_bin'].nunique()}\")\n",
    "print(f\"Year range: {train_binned['production_date'].min():.0f} - {train_binned['production_date'].max():.0f}\")\n",
    "\n",
    "print(f\"\\nTest data:\")\n",
    "print(f\"Samples: {len(test_binned)}\")\n",
    "print(f\"Unique bins: {test_binned['year_bin'].nunique()}\")\n",
    "print(f\"Year range: {test_binned['production_date'].min():.0f} - {test_binned['production_date'].max():.0f}\")\n",
    "\n",
    "print(f\"\\nTop 10 bins (training):\")\n",
    "print(train_binned['year_bin_label'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2),\n",
    "    strip_accents='unicode',\n",
    "    lowercase=True,\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "print(\"\\nFitting TF-IDF on training data...\")\n",
    "X_train_text = vectorizer.fit_transform(train_binned['MERGED'].fillna(''))\n",
    "\n",
    "print(\"Transforming test data...\")\n",
    "X_test_text = vectorizer.transform(test_binned['MERGED'].fillna(''))\n",
    "\n",
    "print(f\"\\nâœ“ TF-IDF complete!\")\n",
    "print(f\"  Train shape: {X_train_text.shape}\")\n",
    "print(f\"  Test shape: {X_test_text.shape}\")\n",
    "print(f\"  Vocabulary: {len(vectorizer.vocabulary_)} features\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d90e99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"STEP: PREPARE FEATURES\")\n",
    "if USE_NUMERICAL_FEATURES:\n",
    "    print(\"\\nAdding numerical features...\")\n",
    "    numerical_features = ['text_length', 'word_count', 'avg_word_length']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_numerical = scaler.fit_transform(train_binned[numerical_features].fillna(0))\n",
    "    X_test_numerical = scaler.transform(test_binned[numerical_features].fillna(0))\n",
    "    \n",
    "    from scipy.sparse import hstack\n",
    "    X_train = hstack([X_train_text, X_train_numerical])\n",
    "    X_test = hstack([X_test_text, X_test_numerical])\n",
    "    \n",
    "    print(f\"  âœ“ Combined features, shape: {X_train.shape}\")\n",
    "else:\n",
    "    print(\"\\nUsing TF-IDF only\")\n",
    "    X_train = X_train_text\n",
    "    X_test = X_test_text\n",
    "    scaler = None\n",
    "\n",
    "y_train = train_binned['year_bin'].values\n",
    "y_test = test_binned['year_bin'].values\n",
    "\n",
    "print(f\"\\nFeatures ready:\")\n",
    "print(f\"  Train: {X_train.shape}\")\n",
    "print(f\"  Test: {X_test.shape}\")\n",
    "print(f\"  Classes: {len(np.unique(y_train))}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b504ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if MODEL_TYPE == 'logistic':\n",
    "    model = LogisticRegression(\n",
    "        max_iter=1000,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        C=1.0,\n",
    "        solver='lbfgs',\n",
    "        verbose=1\n",
    "    )\n",
    "elif MODEL_TYPE == 'random_forest':\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=20,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "print(f\"\\nðŸ”„ Training {MODEL_TYPE} model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"âœ“ Training complete!\")\n",
    "\n",
    "train_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_pred)\n",
    "print(f\"\\nTraining Accuracy: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f150baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 10: SAVE MODEL\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP: SAVE MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "model_info = {\n",
    "    'model': model,\n",
    "    'model_type': MODEL_TYPE,\n",
    "    'bin_size': BIN_SIZE,\n",
    "    'use_numerical': USE_NUMERICAL_FEATURES\n",
    "}\n",
    "\n",
    "with open(MODEL_SAVE_PATH, 'wb') as f:\n",
    "    pickle.dump(model_info, f)\n",
    "print(f\"âœ“ Model saved: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "with open(VECTORIZER_SAVE_PATH, 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "print(f\"âœ“ Vectorizer saved: {VECTORIZER_SAVE_PATH}\")\n",
    "\n",
    "if USE_NUMERICAL_FEATURES and scaler:\n",
    "    with open(SCALER_SAVE_PATH, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    print(f\"âœ“ Scaler saved: {SCALER_SAVE_PATH}\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ce4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 11: PREDICT\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"STEP: PREDICT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nðŸ”„ Making predictions...\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "test_binned['predicted_year_bin'] = y_pred\n",
    "test_binned['predicted_year_bin_label'] = (y_pred.astype(int).astype(str) + '-' + \n",
    "                                           (y_pred + BIN_SIZE - 1).astype(int).astype(str))\n",
    "test_binned['prediction_confidence'] = y_pred_proba.max(axis=1)\n",
    "test_binned['predicted_year'] = y_pred + (BIN_SIZE / 2)\n",
    "test_binned['error_years'] = abs(test_binned['production_date'] - test_binned['predicted_year'])\n",
    "\n",
    "print(f\"âœ“ Predictions complete: {len(y_pred)} samples\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef7b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "exact_match = (y_test == y_pred).sum()\n",
    "within_one = (np.abs(y_test - y_pred) <= BIN_SIZE).sum()\n",
    "\n",
    "print(f\"\\nClassification Metrics:\")\n",
    "print(f\"  Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"  Exact match: {exact_match}/{len(y_test)} ({exact_match/len(y_test)*100:.2f}%)\")\n",
    "print(f\"  Within Â±{BIN_SIZE}y: {within_one}/{len(y_test)} ({within_one/len(y_test)*100:.2f}%)\")\n",
    "\n",
    "# Regression metrics\n",
    "mae = mean_absolute_error(test_binned['production_date'], test_binned['predicted_year'])\n",
    "rmse = np.sqrt(mean_squared_error(test_binned['production_date'], test_binned['predicted_year']))\n",
    "r2 = r2_score(test_binned['production_date'], test_binned['predicted_year'])\n",
    "\n",
    "print(f\"\\nRegression Metrics:\")\n",
    "print(f\"  MAE: {mae:.2f} years\")\n",
    "print(f\"  RMSE: {rmse:.2f} years\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "\n",
    "print(f\"\\nConfidence:\")\n",
    "print(f\"  Mean: {test_binned['prediction_confidence'].mean():.3f}\")\n",
    "print(f\"  High (>0.8): {(test_binned['prediction_confidence'] > 0.8).sum()} ({(test_binned['prediction_confidence'] > 0.8).sum()/len(test_binned)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607625d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics and visualizations\n",
    "print(\"=\"*70)\n",
    "print(\"EVALUATION METRICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Calculate metrics\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "exact_match = (y_test == y_pred).sum()\n",
    "within_bin = (np.abs(y_test - y_pred) <= BIN_SIZE).sum()\n",
    "\n",
    "mae = mean_absolute_error(test_binned['production_date'], test_binned['predicted_year'])\n",
    "rmse = np.sqrt(mean_squared_error(test_binned['production_date'], test_binned['predicted_year']))\n",
    "r2 = r2_score(test_binned['production_date'], test_binned['predicted_year'])\n",
    "\n",
    "print(f\"\\nClassification Metrics:\")\n",
    "print(f\"  Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"  Exact match: {exact_match}/{len(y_test)} ({exact_match/len(y_test)*100:.2f}%)\")\n",
    "print(f\"  Within Â±{BIN_SIZE}y: {within_bin}/{len(y_test)} ({within_bin/len(y_test)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nRegression Metrics:\")\n",
    "print(f\"  MAE: {mae:.2f} years\")\n",
    "print(f\"  RMSE: {rmse:.2f} years\")\n",
    "print(f\"  RÂ²: {r2:.4f}\")\n",
    "\n",
    "print(f\"\\nConfidence:\")\n",
    "print(f\"  Mean: {test_binned['prediction_confidence'].mean():.3f}\")\n",
    "print(f\"  High (>0.8): {(test_binned['prediction_confidence'] > 0.8).sum()} ({(test_binned['prediction_confidence'] > 0.8).sum()/len(test_binned)*100:.1f}%)\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Actual vs Predicted\n",
    "axes[0, 0].scatter(test_binned['production_date'], test_binned['predicted_year'], alpha=0.3, s=10)\n",
    "axes[0, 0].plot([test_binned['production_date'].min(), test_binned['production_date'].max()],\n",
    "                [test_binned['production_date'].min(), test_binned['production_date'].max()],\n",
    "                'r--', lw=2, label='Perfect prediction')\n",
    "axes[0, 0].set_xlabel('Actual Year')\n",
    "axes[0, 0].set_ylabel('Predicted Year')\n",
    "axes[0, 0].set_title('Actual vs Predicted Years')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Error distribution\n",
    "axes[0, 1].hist(test_binned['error_years'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].axvline(mae, color='r', linestyle='--', linewidth=2, label=f'MAE: {mae:.2f}')\n",
    "axes[0, 1].set_xlabel('Absolute Error (years)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Distribution of Prediction Errors')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Confidence distribution\n",
    "axes[1, 0].hist(test_binned['prediction_confidence'], bins=30, edgecolor='black', alpha=0.7, color='green')\n",
    "axes[1, 0].set_xlabel('Confidence Score')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].set_title('Distribution of Prediction Confidence')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Bin distribution\n",
    "bin_counts = test_binned['year_bin_label'].value_counts().sort_index()\n",
    "axes[1, 1].bar(range(len(bin_counts)), bin_counts.values, alpha=0.7, color='orange')\n",
    "axes[1, 1].set_xticks(range(len(bin_counts)))\n",
    "axes[1, 1].set_xticklabels(bin_counts.index, rotation=45, ha='right')\n",
    "axes[1, 1].set_ylabel('Count')\n",
    "axes[1, 1].set_title('Distribution of Predictions by Year Bin')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop predictions by confidence:\")\n",
    "print(test_binned[['production_date', 'predicted_year', 'prediction_confidence', 'error_years']].nlargest(10, 'prediction_confidence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66e5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_numeric = pd.to_numeric(train[\"production_date\"], errors=\"coerce\")\n",
    "oldest_year = int(year_numeric.min() > 1000)\n",
    "print(f\"The oldest production year in the training set is: {oldest_year}\")\n",
    "year_filtered = year_numeric[year_numeric.between(1465, 2025)]\n",
    "print(year_filtered.max())\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(year_filtered.dropna(), bins=80, kde=True, color=\"steelblue\")\n",
    "plt.title(f\"Production year distribution (1465 to 2025)\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e2df8",
   "metadata": {},
   "source": [
    "## REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dd5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"TF-IDF REGRESSION PIPELINE - EXACT YEAR PREDICTION\")\n",
    "\n",
    "\n",
    "MIN_YEAR = 1465\n",
    "MAX_YEAR = 2025\n",
    "MODEL_SAVE_PATH = \"./tfidf_regression_model.pkl\"\n",
    "VECTORIZER_SAVE_PATH = \"./tfidf_regression_vectorizer.pkl\"\n",
    "\n",
    "print(f\"Year range: {MIN_YEAR}-{MAX_YEAR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f71e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"STEP: PREPROCESS FOR REGRESSION\")\n",
    "\n",
    "def preprocess_for_regression(df, min_year=1465, max_year=2025):\n",
    "    \"\"\"Filter years and prepare for regression\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Handle missing dates\n",
    "    missing = df['production_date'].isna().sum()\n",
    "    if missing > 0:\n",
    "        median = df['production_date'].median()\n",
    "        df['production_date'] = df['production_date'].fillna(median)\n",
    "        print(f\"  Filled {missing} missing dates with median: {median:.0f}\")\n",
    "    \n",
    "    # Filter year range\n",
    "    before = len(df)\n",
    "    df = df[(df['production_date'] >= min_year) & (df['production_date'] <= max_year)]\n",
    "    removed = before - len(df)\n",
    "    print(f\"  Filtered {min_year}-{max_year}: removed {removed} rows ({removed/before*100:.2f}%)\")\n",
    "    print(f\"  Final: {len(df)} samples, years {df['production_date'].min():.0f}-{df['production_date'].max():.0f}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_reg = preprocess_for_regression(merged_train, MIN_YEAR, MAX_YEAR)\n",
    "test_reg = preprocess_for_regression(test, MIN_YEAR, MAX_YEAR)\n",
    "\n",
    "print(f\"\\nâœ“ Train: {train_reg.shape}, Test: {test_reg.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8251efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    min_df=3,\n",
    "    max_df=0.8,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words='english',\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "print(\"Fitting TF-IDF...\")\n",
    "X_train = vectorizer.fit_transform(train_reg['MERGED'].fillna(''))\n",
    "X_test = vectorizer.transform(test_reg['MERGED'].fillna(''))\n",
    "\n",
    "y_train = train_reg['production_date'].values\n",
    "y_test = test_reg['production_date'].values\n",
    "\n",
    "print(f\"âœ“ Train: {X_train.shape}, Test: {X_test.shape}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41acc7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 4: TRAIN REGRESSION MODEL\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "\n",
    "model = Ridge(alpha=1.0, random_state=42)\n",
    "\n",
    "print(\"Training...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_pred = model.predict(X_train)\n",
    "train_mae = np.abs(train_pred - y_train).mean()\n",
    "\n",
    "print(f\"âœ“ Training MAE: {train_mae:.2f} years\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f3ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "with open(MODEL_SAVE_PATH, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print(f\"âœ“ Model: {MODEL_SAVE_PATH}\")\n",
    "\n",
    "with open(VECTORIZER_SAVE_PATH, 'wb') as f:\n",
    "    pickle.dump(vectorizer, f)\n",
    "print(f\"âœ“ Vectorizer: {VECTORIZER_SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792b3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "test_reg['predicted_year_regression'] = y_pred\n",
    "test_reg['error_regression'] = np.abs(test_reg['production_date'] - y_pred)\n",
    "\n",
    "print(f\"âœ“ Predictions: {len(y_pred)} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f522b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "median_ae = np.median(np.abs(y_test - y_pred))\n",
    "\n",
    "print(f\"\\nMetrics:\")\n",
    "print(f\"  MAE:    {mae:.2f} years\")\n",
    "print(f\"  Median: {median_ae:.2f} years\")\n",
    "print(f\"  RMSE:   {rmse:.2f} years\")\n",
    "print(f\"  RÂ²:     {r2:.4f}\")\n",
    "\n",
    "print(f\"\\nError Distribution:\")\n",
    "print(f\"  <15y:  {(test_reg['error_regression'] < 15).sum()} ({(test_reg['error_regression'] < 15).mean()*100:.1f}%)\")\n",
    "print(f\"  <30y:  {(test_reg['error_regression'] < 30).sum()} ({(test_reg['error_regression'] < 30).mean()*100:.1f}%)\")\n",
    "print(f\"  <50y:  {(test_reg['error_regression'] < 50).sum()} ({(test_reg['error_regression'] < 50).mean()*100:.1f}%)\")\n",
    "print(f\"  >100y: {(test_reg['error_regression'] > 100).sum()} ({(test_reg['error_regression'] > 100).mean()*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1defc01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CELL 8: SAMPLE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "sample = test_reg[['MERGED', 'production_date', 'predicted_year_regression', 'error_regression']].head(15).copy()\n",
    "sample['MERGED'] = sample['MERGED'].str[:70] + '...'\n",
    "sample['predicted_year_regression'] = sample['predicted_year_regression'].round(1)\n",
    "sample['error_regression'] = sample['error_regression'].round(1)\n",
    "\n",
    "print(\"\\n\" + sample.to_string(index=False))\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66785c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== TRAINING DATA DIAGNOSTICS ===\")\n",
    "print(merged_train['production_date'].describe())\n",
    "print(f\"NaN count: {merged_train['production_date'].isna().sum()}\")\n",
    "print(f\"Data type: {merged_train['production_date'].dtype}\")\n",
    "print(f\"Sample values: {merged_train['production_date'].head()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
